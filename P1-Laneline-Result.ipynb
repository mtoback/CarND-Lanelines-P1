{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#importing some useful packages\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "import cv2\n",
    "from skimage.feature._canny import canny\n",
    "import sys\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# filter a copy of an image for color\n",
    "def process_image_color(img, rgb_threshold):\n",
    "    color_select = np.copy(img)\n",
    "\n",
    "    # ### Mask pixels below the threshold\n",
    "    color_thresholds = (color_select[:,:,0] < rgb_threshold[0]) | \\\n",
    "        (color_select[:,:,1] < rgb_threshold[1]) | \\\n",
    "        (color_select[:,:,2] < rgb_threshold[2])\n",
    "    return (color_select, color_thresholds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define trianglular region\n",
    "def build_triangle(img, apex, right, left):\n",
    "    # ### Get Image size \n",
    "    ysize = img.shape[0]\n",
    "    xsize = img.shape[1]\n",
    "    # ### Define the vertices of a quadrillateral mask.\n",
    "    # Keep in mind the origin (x=0, y=0) is in the upper left\n",
    "    apex = [apex[0]*xsize, apex[1]*ysize]\n",
    "    right_bottom = [right*xsize, ysize-1]\n",
    "    left_bottom = [left*xsize, ysize-1]\n",
    "    \n",
    "    # Fit lines (y=Ax+B) to identify the  3 sided region of interest\n",
    "    # np.polyfit() returns the coefficients [A, B] of the fit\n",
    "    fit_left = np.polyfit((left_bottom[0], apex[0]), (left_bottom[1], apex[1]), 1)\n",
    "    fit_right = np.polyfit((right_bottom[0], apex[0]), (right_bottom[1], apex[1]), 1)\n",
    "    fit_bottom = np.polyfit((left_bottom[0], right_bottom[0]), (left_bottom[1], right_bottom[1]), 1)\n",
    "    \n",
    "    # Find the region inside the lines\n",
    "    XX, YY = np.meshgrid(np.arange(0, xsize), np.arange(0, ysize))\n",
    "    region_thresholds = (YY > (XX*fit_left[0] + fit_left[1])) & \\\n",
    "                        (YY > (XX*fit_right[0] + fit_right[1])) & \\\n",
    "                        (YY < (XX*fit_bottom[0] + fit_bottom[1]))\n",
    "    return region_thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# mask image based on color and region limits\n",
    "def mask_image(img, color_thresholds, region_thresholds):\n",
    "    # Mask color and region selection\n",
    "    img[color_thresholds | ~region_thresholds] = [0, 0, 0]\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process_canny(color_select, kernel_size, canny_thresholds):\n",
    "    gray = cv2.cvtColor(color_select, cv2.COLOR_RGB2GRAY)\n",
    "    blur_gray = cv2.GaussianBlur(gray,(kernel_size, kernel_size),0)\n",
    "    # Execute Canny\n",
    "    # Define our parameters for Canny and run it\n",
    "    edges = cv2.Canny(blur_gray, canny_thresholds[0], canny_thresholds[1])\n",
    "    # Display the image\n",
    "    return edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def hough_transform(hough_params, image):\n",
    "    \n",
    "    # Run Hough on edge detected image\n",
    "    # Output \"lines\" is an array containing endpoints of detected line segments\n",
    "    lines = cv2.HoughLinesP(image, hough_params['rho'], \n",
    "                            hough_params['theta'], \n",
    "                            hough_params['threshold'], \n",
    "                            np.array([]),\n",
    "                            hough_params['min_line_length'], \n",
    "                            hough_params['max_line_gap'])\n",
    "    return lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_lanelines(img, lines):\n",
    "    # Iterate over the output \"lines\" and draw lines on a blank image\n",
    "    for line in lines:\n",
    "        for x1,y1,x2,y2 in line:\n",
    "            cv2.line(img,(x1,y1),(x2,y2),(0,0,255),2)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_lanelines(color_select, params, color_thresholds, debug=False):\n",
    "    region_thresholds = build_triangle(color_select, params['apex'],\n",
    "                                       params['right'], params['left'])\n",
    "    \n",
    "    color_select = mask_image(color_select, color_thresholds, region_thresholds)\n",
    "    if debug:\n",
    "        display_image(\"masked image\",color_select)\n",
    "    edges = process_canny(color_select, params['kernel_size'], params['canny_thresholds'])\n",
    "    if debug:\n",
    "        display_image(\"canny output\", edges)\n",
    "    lines = hough_transform(params['hough_params'], edges)\n",
    "    return lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def define_params():\n",
    "    params = {}\n",
    "    # ### Define color selection criteria\n",
    "    red_threshold = 100\n",
    "    green_threshold = 100\n",
    "    blue_threshold = 0\n",
    "    params['rgb'] = [red_threshold, green_threshold, blue_threshold]\n",
    "    \n",
    "    # Define a kernel size for Gaussian smoothing / blurring\n",
    "    params['kernel_size'] = 5 # Must be an odd number (3, 5, 7...)\n",
    "    # define canny low and high thresholds\n",
    "    params['canny_thresholds'] = (100, 200)\n",
    "    # Define the Hough transform parameters\n",
    "    hough_params = {}\n",
    "    hough_params['rho'] = 2 # distance resolution in pixels of the Hough grid\n",
    "    hough_params['theta'] = np.pi/180 # angular resolution in radians of the Hough grid\n",
    "    hough_params['threshold'] = 25     # minimum number of votes (intersections in Hough grid cell)\n",
    "    hough_params['min_line_length'] = 100 #minimum number of pixels making up a line\n",
    "    hough_params['max_line_gap'] = 40    # maximum gap in pixels between connectable line segments\n",
    "    params['hough_params'] = hough_params\n",
    "    params['apex'] = (0.48, 0.58)\n",
    "    params['right'] = 0.93\n",
    "    params['left'] = 0.15\n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def process_image(image):\n",
    "    # NOTE: The output you return should be a color image (3 channel) for processing video below\n",
    "    # TODO: put your pipeline here,\n",
    "    # you should return the final output (image with lines are drawn on lanes)\n",
    "    params = define_params()\n",
    "    (color_select, color_thresholds) = process_image_color(image, params['rgb'])\n",
    "    lines = get_lanelines(color_select, params, color_thresholds)\n",
    "    result = image\n",
    "    if lines is not None:\n",
    "        result = add_lanelines(image, lines)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Import everything needed to edit/save/watch video clips\n",
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] >>>> Building video white.mp4\n",
      "[MoviePy] Writing video white.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████▊| 221/222 [00:09<00:00, 23.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Done.\n",
      "[MoviePy] >>>> Video ready: white.mp4 \n",
      "\n",
      "Wall time: 9.67 s\n"
     ]
    }
   ],
   "source": [
    "white_output = 'white.mp4'\n",
    "clip1 = VideoFileClip(\"solidWhiteRight.mp4\")\n",
    "white_clip = clip1.fl_image(process_image) #NOTE: this function expects color images!!\n",
    "%time white_clip.write_videofile(white_output, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<video width=\"960\" height=\"540\" controls>\n",
       "  <source src=\"white.mp4\">\n",
       "</video>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(white_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] >>>> Building video yellow.mp4\n",
      "[MoviePy] Writing video yellow.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████▉| 681/682 [00:26<00:00, 23.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Done.\n",
      "[MoviePy] >>>> Video ready: yellow.mp4 \n",
      "\n",
      "Wall time: 26.9 s\n"
     ]
    }
   ],
   "source": [
    "yellow_output = 'yellow.mp4'\n",
    "clip2 = VideoFileClip('solidYellowLeft.mp4')\n",
    "yellow_clip = clip2.fl_image(process_image)\n",
    "%time yellow_clip.write_videofile(yellow_output, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<video width=\"960\" height=\"540\" controls>\n",
       "  <source src=\"yellow.mp4\">\n",
       "</video>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(yellow_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] >>>> Building video extra.mp4\n",
      "[MoviePy] Writing video extra.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 251/251 [00:17<00:00, 14.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Done.\n",
      "[MoviePy] >>>> Video ready: extra.mp4 \n",
      "\n",
      "Wall time: 18.1 s\n"
     ]
    }
   ],
   "source": [
    "challenge_output = 'extra.mp4'\n",
    "clip2 = VideoFileClip('challenge.mp4')\n",
    "challenge_clip = clip2.fl_image(process_image)\n",
    "%time challenge_clip.write_videofile(challenge_output, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<video width=\"960\" height=\"540\" controls>\n",
       "  <source src=\"extra.mp4\">\n",
       "</video>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(challenge_output))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reflections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pipeline is as follows. \n",
    "First, one puts a color filter through to accentute the lighter colors. \n",
    "\n",
    "Second a visual triangle is setup to block out anything not directly in front of the vehicle and out to about half way up the picture, where perspective would have the lane lines merge. It is assumed that this triangle would be fixed for a given fixed camera on the vehicle. \n",
    "\n",
    "At that point, one can convert the picture to greyscale and perform canny and hough transforms. \n",
    "The result should be a pair of lines that can be superimposed on the original color frame.\n",
    "\n",
    "The first videos have a clear shot at the road while the challenge does not. Short of adjusting the camera angle, ignoring the bottom 50 or 60 pixels. \n",
    "\n",
    "Also, it appears that the yellow color is darker and we're not picking it up in the filters. By changing the rgb threshold from (120, 120, 120) to (100,100,0) I was able to pickup more of the lane lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
